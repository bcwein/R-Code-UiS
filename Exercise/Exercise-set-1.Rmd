---
title: "Exercise set 1 - Week 35"
author: "Bj√∏rn Christian Weinbach"
date: 20.08.2020
output:
  pdf_document: default
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

This notebook is shows my solution to the exercise sheet for week 35 in STA510 course at the University of Stavanger.

# Import libraries

```{r}
library(ggplot2)    # Library for plotting
```

# Problem 1

Consider the experiment of flipping an unbiased coin 5 independent times. Let H 
denote the outcome "head" and T to denote "tails".

\begin{enumerate}
  \item Compute the probability of HHTHT and THHHT.
  \newcounter{enumTemp}
  \setcounter{enumTemp}{\theenumi}
\end{enumerate}

We have two events, HHTHT and THHHT which are two events in the sample space of
all possible outcomes of 5 coin flips, the probability $P(\text{HHTHT}) / n$ 
where $n$ is all possible outcomes.

$n$ can be calculated using the \textbf{fundemental counting principle} which 
gives us:

\begin{equation}
n = 2*2*2*2*2 = 2^5 = 32
\end{equation}

Therefore, for each of the two events above, the probability of one of them
occuring is $1/32$.

\begin{enumerate}
  \setcounter{enumi}{\theenumTemp}
  \item \label{simulation} Modify the R-code from the number of heads example
  in the lectures to simulate the probability of three heads occurring in the 5 trials.
  \setcounter{enumTemp}{\theenumi}
\end{enumerate}

## Function for simulationg number of heads
```{r}
# Simulate the number of heads in k throws of a dice repeated Nsim times
# We let 0 correspond to tail and 1 correspond to head,
# The sample()-command below randomly draw a 0 or 1 with 
# equal probability k times, and then sum() will summarize the number of heads
simheads <- function(Nsim,k){
  nheads <- vector(length=Nsim) # Define a vector to store the number of heads 
  for(i in 1:Nsim)              # Generate the number of heads Nsim times
    nheads[i] <- sum(sample(0:1,size=k,replace=TRUE))  # See explanation above
  return(nheads)                # Return the resulting vector
}
```
## Simulate and plot barplot
```{r}
# Summarize the results by histograms and numbers
# Repeat the lines below many times for different numbers of Nsim and k
# What happens when Nsim gets large?
k <- 5
Nsim <- 1000
nheadsim <- simheads(Nsim=Nsim,k=k)
relfreq <- table(nheadsim)/Nsim # Calculate relative frequency for each outcome
relfreq
barplot(relfreq,ylab="Relative frequency")
```
## Exact probability
We introduce the random variable $X = \text{number of heads}$. The exact
probability $P(X = 3)$ is calculated using the binomial distribution with
parameters $n = 3$ and $p = 0.5$.

In R, this is done so:

```{r}
x <- dbinom(3, size=5, prob=0.5)
print(x)
```
Which tells us that the probability of getting 3 heads out of 5 coin tosses
is 31.25 \%.

\begin{enumerate}
  \setcounter{enumi}{\theenumTemp}
  \item Redo point \ref{simulation} for a biased coin for which the probability
  of heads is 0.6.
  \setcounter{enumTemp}{\theenumi}
\end{enumerate}

## Biased function
```{r}
# Same function as above but with a biased coin. b is bias variable
simbias <- function(Nsim,k,b){
  nheads <- vector(length=Nsim) # Define a vector to store the number of heads
  for(i in 1:Nsim)              # Generate the number of heads Nsim times
    nheads[i] <- sum(sample(0:1,size=k,replace=TRUE, prob=c(1-b, b)))
  return(nheads)                # Return the resulting vector
}
```

## Simulate and summarise

```{r}
# Summarize the results by histograms and numbers
# Repeat the lines below many times for different numbers of Nsim and k
# What happens when Nsim gets large?
k <- 5
Nsim <- 1000
b <- 0.6
nheadsim <- simbias(Nsim=Nsim,k=k,b=b)
relfreq <- table(nheadsim)/Nsim # Calculate relative frequency for each outcome
relfreq
barplot(relfreq,ylab="Relative frequency")
```

# Problem 2

For each of the following, determine the constant c such that f(x) satises the
condition of being the probability mass function (pmf) for a discrete random 
variable X, and then depict each f(x) as a bar graph:

## a)
Given the function

\begin{equation}
f(x) = x/c, \quad x = 1,2,3,4
\end{equation}

for the function qualify as a pmf the constant $c$ should have a value such that

\begin{equation}
\sum_{i = 1}^{4} f(x_i) = 1
\end{equation}

Therefore, c can be calculated as follows

\begin{equation}
1/c + 2/c + 3/c + 4/c = 1 \implies c = 10
\end{equation}

## The function i R
```{r}
# Define f1(x)
# The function takes in a vecor and checks if it is valid
# function calculates pmf
f1 <- function(x) {
  ifelse(x %in% c(1, 2, 3, 4),
         x/10,
         0)
}

barplot(f1(1:4),ylab="Relative frequency", xlab="x")
```
we see that the function is a valid pmf since:

```{r}
sum(f1(-100:100))
```

## b)

Given the function

\begin{equation}
f(x) = c(x + 1)^2, \quad x = 0,1,2,3
\end{equation}

for the function qualify as a pmf the constant $c$ should have a value such that

\begin{equation}
\sum_{i = 0}^{3} f(x_i) = 1
\end{equation}

Therefore, c can be calculated as follows

\begin{equation}
c + 4c + 9c = 1 \implies c = 1/14
\end{equation}

## The function in R
```{r}
# Define f2(x)
# The function takes in a vector and checks if it is valid
# function calculates pmf
f2 <- function(x) {
  ifelse(x %in% c(1, 2, 3, 4),
         (1/14)*(x + 1),
         0)
}

barplot(f2(0:3),ylab="Relative frequency", xlab="x")
```

we see that the function is a valid pmf since:

```{r}
sum(f2(-100:100))
```

# Problem 3
For the probability distributions in problem 2 find $E(X)$ and $E(g(X))$ with 
$g(x) = x^3$.

## Function for expected value

```{r}
expected <- function(func, vec)
  return(sum(vec * func(vec)))
``` 

## Expected value of f1 and f2

```{r}
expected(f1, c(1,2,3,4))
expected(f2, c(1,2,3,4))
```

## Funcion for expected value with $g(x)$

```{r}
gexpected <- function(func, vec, gvec)
  return(sum(gvec * func(vec)))
``` 

## Expected value $E(g(x))

```{r}
gexpected(f1, c(1,2,3,4), c(1,2,3,4)^3)
gexpected(f2, c(1,2,3,4), c(1,2,3,4)^3)
```

# Problem 4

## a)

Calculate $P(X < 0.5)$

$P(X < 0.5)$ is calculated using the integral

\begin{equation}
\int_{-\infty}^{0.5} f(x) dx
\end{equation}

where $f(x)$ is the probability density function for $X$

### Calculate $P(X < 0.5)$ in R
```{r}
f3 <- function(x) {
  if (x >= 0 && x <= 1) {
    return(4*x*(1 - x^2))
  } else {
    return(0)
  } 
}


integrate(Vectorize(f3),
         lower=-Inf,
         upper=0.5)$value
```

### Calculate E(X)

```{r}
integrate(Vectorize(function(x) x * f3(x)),
          lower = -Inf,
          upper = Inf)$value
```
### Calculate Var(X)

```{r}
integrate(Vectorize(function(x) x^2 * f3(x)),
          lower = -Inf,
          upper = Inf)$value
```
### Calculate SD(X)

```{r}
sqrt(integrate(Vectorize(function(x) x^2 * f3(x)),
          lower = -Inf,
          upper = Inf)$value)
```

## b) Calculate $P(X < 0.7)$ and $P(X > 7)$

### $P(X < 0.7)$
```{r}
integrate(Vectorize(f3),
         lower=-Inf,
         upper=0.7)$value
```

### $P(X < 0.7)$
```{r}
1 - integrate(Vectorize(f3),
              lower=-Inf,
              upper=0.7)$value
```
## c) Plot $f(x)$

```{r}
x <- seq(0, 1, 0.01)
plot(x, f3(x), type="l", col= "blue")
```

## c) Plot $F(x)$

```{r}
F3 <- function(x) {
  return(-4*((x^4 / 4)-(x^2 / 2)))
}

x <- seq(0, 1, 0.01)
plot(x, F3(x), type="l", col= "blue")
```

# Problem 5

Let X be a continuous random variable with pdf

\begin{equation}
f(x) =  \left\{
          \begin{array}{ll} k(1 - x^2) \quad ,-1 \leq x \leq 1 \\ 
          0 \quad \text{otherwise} \end{array}
        \right. 
\end{equation}

where k is a constant.

a. Determine k and make a sketch of f(x) in R.

to determine k, we use the fact that $f(x)$ is a pdf which implies that the
following integral

\begin{equation}
\int_{-\infty}^{\infty} f(x) dx = 1
\end{equation}

since the pdf is 0 for all x besides $x \in [-1, 1]$ we calculate

\begin{equation}
k \int_{-1}^{1} (1 - x^2) dx = k[1 - \frac{1}{3} + 1 - \frac{1}{3}]
= \frac{4}{3}k = 1 \implies k = \frac{3}{4}
\end{equation}

This can also be validated in R

```{r}
f4 <- function(x) {
  return(3/4 * (1 - x^2))
}

integrate(f4,
          lower = -1,
          upper = 1)$value
```
## Plot $f(x)$

```{r}
x <- seq(-1, 1, 0.01)
plot(x, f4(x), type="l", col= "blue")
```

b. Calculate $P(X < 0.5)

```{r}
integrate(f4,
          lower = -1,
          upper = 0.5)$value
```
c. Let $Y = 1 + x^2$ Calculate $E(Y)$

We know from Theorem 4.5 in Walpole, Ronald E., et al.

\begin{equation}
E(aX + b) = aE(X) + b
\end{equation}

This gives us that

\begin{equation}
E(Y) = E(aX^2 + b) = aE(X^2) + b 
\end{equation}

```{r}
# Function for linear combination of random variable
expectedLinearComb <- function(g, f, lower, upper, a, b) {
  return (a*integrate(Vectorize(function(x) g(x) * f(x)),
          lower = lower,
          upper = upper)$value + b)
}

g <- function(x) x^2
expectedLinearComb(g, f4, -1, 1, 1, 1)
```
# Problem 6

```{r}
xi = c(13.89, 13.39, 12.20, 14.35, 14.10, 13.39, 13.96, 14.15, 13.69, 12.57)
yi = c(13.99, 13.39, 12.65, 14.25, 13.99, 13.09, 13.66, 14.25, 13.36, 12.57)

df <- data.frame("X" = xi, "Y" = yi)

ggplot(df, aes(x=X, y=Y)) + 
geom_point(shape=18, color="red")+
geom_smooth(method=lm,  linetype="dashed",
           color="blue", fill="blue")
```


## Calculate correlation

```{r}
cor(xi, yi)
```

# Problem 7

10 people are trying to identify one pepsi out of 5 total sodas.
Given the null-hypothesis that pepsi and cola taste the same, there is a 
$\frac{1}{5}$ probability of choosing the correct one.

The 10 experiments across 10 people are independent and can be seen as repeated
trials. The variable $X$ is therefore a binomial distrobution with parmeters 
$p=\frac{1}{5}$ and $n = 10$

We do the calculations in R

## R code calculating $P(X \leq 3)$

```{r}
# Calculate P(X >= 3)
px = pbinom(3, size=10, prob=0.2, lower.tail = FALSE)
print(px)
```

## R code calculating $E(X)$

```{r}
# Calculate E(X)
f5 = function(x) dbinom(x, size=10, prob=0.2)
mu = sum(0:10*f5(0:10))
mu
```

## R code calculating $Var(X)$

```{r}
# Calculate Var(X)
sum((0:10)**2 * f5(0:10)) - mu**2
```

b. Let us now imagine that the test goes on and on (with more than 10 persons 
if necessary) and let N be the number of persons needed for the first correct 
identification. What kind of distribution does N have and what is E(N)?

This is example follows the properties for a geometric distribution.

Geometric distribution has a infinite number of elements, since there is
always a possibility, though an unlikely one, that we need N trials until
success where N approaches infinity.

# Problem 8
 
The height of Norwegian men in their twenties follows a normal distribution with
mean 180 cm and standard deviation 6.5 cm.

Use the R function pnorm to calculate the following probabilities:

a. The probability that at man has a height of less than 175.

```{r}
# Calculate P(X < 175cm)
pnorm(175, mean = 180, sd = 6.5, lower.tail = TRUE, log.p = FALSE)
```
b. The probability that at man has a height of more than 190.
```{r}
# Calculate P(X > 190cm)
pnorm(190, mean = 180, sd = 6.5, lower.tail = FALSE, log.p = FALSE)
```
c. The probability that at man has a height between 170 to 180.

```{r}
# Calculate P(170cm < X < 180cm)
pnorm(180, mean = 180, sd = 6.5, lower.tail = TRUE, log.p = FALSE) -
pnorm(170, mean = 180, sd = 6.5, lower.tail = TRUE, log.p = FALSE)
```
d. The height which is such that only 1% of the men have a higher height.
Problem

```{r}
qnorm(0.99, mean = 180, sd = 6.5, lower.tail = TRUE, log.p = FALSE)
```

# Problem 9

```{r}
# All random variables has same expected value

ex = 0.4
ey = 0.4
ez = 0.4
vx = 0.1
vy = 0.1
vz = 0.1
corxy = 0 
corxz = 0.5
coryz = -0.5

# 2X
e2x = ex+ex
e2x
v2x = vx + vx
v2x

# X + Y
exy = 2*ex
exy
vxy = vx + vy + 2*(corxy/(sqrt(vx)*sqrt(vy)))
vxy

# X + Z
exz = ex + ez
exz
vxz = vx + vx + 2*(corxz/(sqrt(vx)*sqrt(vz)))
vxz

# Y + Z
eyz = ey + ez
eyz
vyz = vy + vx + 2*(coryz/(sqrt(vy)*sqrt(vz)))
vyz
```
